---
title: "Strategic Plan Word Cloud"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Preliminaries

Please load the following libraries: 

```{r, message=FALSE, warning=FALSE}
# Load relevant libraries
library(pdftools)
library(tm)
library(SnowballC)
library(wordcloud)
library(tidyverse)
library(knitr)
```

The following script assumes that all of the strategic plans listed in the spreadsheet stored in the repository's "data" folder are downloaded as PDFs to your R working directory. 

## Create vector of plan document names

In the following, we make a vector of the names of strategic plan file names (all plans are stored as PDFs in the working directory): 

```{r, echo=-1, message=FALSE, warning=FALSE}
setwd("~/Documents/strategic_plans/update")
# Make a vector of the names of the PDF files (i.e. plan documents) in working directory
files<-list.files(pattern="pdf$")
```

## Make corpus and term document matrix

We will now use the vector of plan document names to make a corpus based on the underlying text of the strategic plans; this corpus is assigned to an object named ```corpus_plans```:

```{r, message=FALSE, warning=FALSE}
# Makes corpus based on strategic plan documents
corpus_plans<-Corpus(URISource(files),readerControl = list(reader=readPDF))
```

Now, we use the corpus as an argument in the ```TermDocumentMatrix``` function to make a term document matrix derived from the corpus. This term document matrix is assigned to an object named ```plans.tdm```

```{r, message=FALSE, warning=FALSE}
# Make term document matrix based on corpus_plans object
plans.tdm <- as.matrix(TermDocumentMatrix(corpus_plans, 
                                control = 
                                  list(removePunctuation = TRUE,
                                       stopwords = TRUE,
                                       tolower = TRUE,
                                       stemming = FALSE,
                                       removeNumbers = TRUE,
                                       bounds = list(global = c(3, Inf)))))  
```

## The Frequency of "Commons" in the Plan Corpus

How many times does the word "commons" appear in the corpus of strategic plans. To find out, we extract a vector that sums up the number of times various words appear in the corpus using the ```rowSums``` function, and assign this vector to an object called ```words```; we then create a data frame based on ```words```, with one column (named "word") containing the various words in the corpus, and the other column (named "freq") containing information on how many times the associated word appears in the corpus. We then extract the row with the words "commons" and "library" (as a reference point) to see how many times they appear in the corpus. 

```{r}
# Extract vector containing information on word frequencies
words <- sort(rowSums(plans.tdm), decreasing=TRUE)
# Create a data frame based on the information in "words"
df <- data.frame(word = names(words),freq=words)
# Find the frequency of "commons" and "library" in the corpus 
df %>% filter(word=="commons"|word=="library") %>% remove_rownames()
```

## Make Word Cloud 

```{r, message=FALSE, warning=FALSE}
# Set seed for reproducibility
set.seed(1234)
# Generate word cloud
wordcloud(words = df$word, freq = df$freq, min.freq = 50, max.words=90, random.order=FALSE, rot.per=0.35, colors=brewer.pal(8, "Dark2"))
```

